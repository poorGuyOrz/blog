---
title: "大数据"
date: 2022-03-14T19:57:11+08:00
draft: true
---

# 大数据

* 数据收集
    要求从数据源收集数据，一般需要考虑多数据源的情况
* 数据存储
    收集数据之后，如果需要进行批处理，则需要存储一段时间的数据
* 数据流处理
    如果不需要，则可以进行流处理，然后存储数据处理之后的数据
* 数据批处理
    数据存储之后， 可以使用批处理处理数据
* 数据的应用
    最后是使用处理之后的数据进行数据分析或者数据挖掘等操作


## 数据存储

* 非结构化或者半结构化数据
* 分布式
* HDFS
* hbase

## 数据处理
* 流处理
    对于实时性要求较高，在数据收集的时候就需要对数据进行处理，数据收集完成时候要求数据也处理完成，
    * Spark
    * Streaming
    * Stom
* 批处理
    不要求实时性，通常是对离线数据进行处理，例如年度数据报表等
    * MapReduce
    * Spark
    * Flink


### MP和Spark作业的差别

* mp是数据分区处理然后再聚合的操作，再设计之初，他的一次作业就是一个完整的mp过程，结果需要写进磁盘，如果有复杂的任务，则需要多个mp作业协同调度，会增加IO的开销
* Spark优化此过程，中间结果使用内存保存，理论上说。MP在后期演化迟早会优化此问题，但是被Spark提前了
* 且Spark使用了RDD，各位灵活
* 他们之间的根本差别就是多个作业之间的通信方式，见一二点
* Spark使用线程调度作业，MP使用进程
* Spark在shuffle的时候才写磁盘
* 内存资源充足的时候选择Spark，否则使用MP




上述的框架是需要进行编码的，但是这不是普通的运维人员可以操作的，所以在上面的框架的基础上的，开发了对外的SQL接口，例如hive，实际上把SQL转换为mp作业，Spark SQL 将 SQL 转换为一系列的 RDDs 和转换关系（transformations），Phoenix 将 SQL 查询转换为一个或多个 HBase Scan。


日志收集框架：Flume 、Logstash、Kibana

分布式文件存储系统：Hadoop HDFS

数据库系统：Mongodb、HBase

分布式计算框架：

批处理框架：Hadoop MapReduce
流处理框架：Storm
混合处理框架：Spark、Flink
查询分析框架：Hive 、Spark SQL 、Flink SQL、 Pig、Phoenix

集群资源管理器：Hadoop YARN

分布式协调服务：Zookeeper

数据迁移工具：Sqoop

任务调度框架：Azkaban、Oozie

集群部署和监控：Ambari、Cloudera Manager



## HDFS

分布式文件系统，主从架构，一个nn，多个dn，
* namenode
    记录元数据信息，例如文件快的位置，文件的打开关闭等
* datanode
    实际的储存的存储节点，执行客户端的读写请求

* 多副本
    hdfs的特点是廉价的机器存储数据，所以需要多副本