---
title: "面试"
date: 2022-03-24T20:26:11+08:00
draft: false
---

# 面试

只是一个技术汇总


----------------------------


* C++基础               [2 days] [课程- https://github.com/parallel101/course.git]
    * 内存
        * 内存结构      [https://segmentfault.com/a/1190000039348996]
            | c++ 编译出来的是可执行文件，是ELF格式的，他本来就有一些格式上的划分，C++在他的基础上进行了更细的划分，分为五个部分，从高地址到底地址依次为：  
                ---
                1. 内核虚拟内存  
                    进程的虚拟印象
                2. 栈  
                    程序自动控制，具体为程序的函数调用，保存局部变量，有大小，可以使用ulimit -s 查看，也可以自行设置，但是建议系统默认即可
                    * 函数调用机制  
                        调用的时候是一个一个的栈帧，函数参数会在调用者的栈帧中开辟空间，从右到左，所以函数列表的默认值必须从右到左的初始化， 可能和这个有关系，然后被调用者构造栈帧，依次执行
                        
                3. 共享库的内存印象
                3. 堆  
                    空间有程序员自行维护，向上增长(TIPS: 由于C的历史原因，C++的内存结构还是说堆区，但是在区别new/malloc 和delete/free 的时候，他们的差别之一可能会在内存上有点区别
                    C的malloc/free可能会说是在堆上分配空间，但是对于C++可能会说的是在自由存储区上分配，自由存储区和堆是不同的概念，堆是操作系统上的概念，但是自由存储区是一个抽象概念
                    一般new可以是在堆上分配空间，但是可能存在在其他情况，例如在栈上使用new，所以他们不是一个概念，面试的时候说到这里，可以装逼😎)
                4. 可写/全局区
                    对应elf中data段和bss段，data段保存的是已初始化的全局变量或者静态变量，bss保存的是未初始化的数据
                5. 只读区
                    text段，保存编译之后的指令，不可变
                6. 常量区
                    保存全局变量，不可变，rodata段，记得使用其他手段去尝试修改常量的时候会报错。  
                    TIPS: const修饰的参数不一定是常量，例如他修饰一个函数的参数的时候，参数还是只是在栈中，只是约定不能修改。
                7. 未使用
        * 内存管理
            * new
                C++有对象的概念，所以他的new大意上是malloc的封装，先申请对象的内存空间，然后调用对象的构造函数构造对象，用在数组上是，先申请所有的空间，然后再依次调用构造函数
            * delete
                删除对象，先调用析构函数，然后再释放空间
                * 对象数组
                    如果调用的是delete[]，如果是基础类型，则删除的时候使用delete和delete[] 都没有区别，因为空间连续的，有额外的空间记录内存的大小，直接使用delete的时候可以直接伤处 如果是自定义对象，如果有指针这类的属性，则必须调用delete[]，
                    否则他只会调用第一个对象的析构函数，可能会导致内存泄露  


            --  new malloc 的区别
                --
                1. 空间分配的概念上
                    一个是堆区，一个是自由存储区
                2. 使用上
                    new会调用构造函数，且new会自行计算对象所需的空间大小，malloc需要自行指定
                3. 概念上
                    malloc是标准函数，而new是关键字
        * 虚表
            * [实现](https://www.zhihu.com/question/389546003/answer/1194780618)  
                虚表是多态的一种实现，但是不是C++的规定，而是编译器的自行的实现方法，在函数中只要声明虚函数，则对象中就会有额外的空间用于保存虚表，他是一个指针，指向虚表，所以对于有虚表的对象
                sizeof的时候会计算这个指针的大小，指针指向虚表的第三个槽位，gdb查看地址的时候会显示+16的字样，因为这是实际的函数指针的开始位置，前两个槽位一个一般是0，拎一个一般是typeinfo的地址，
                虚表和他的附属信息在内存中都是一起的，其实从根本原理上来说，他只是做了一层转换，实际上函数的调用最终的实现都是面向过程的函数的调用，函数才是C++ 的核心，  
                而且虚表由于调用的时候需要寻址，所以会导致性能问题，主要是由于需要进行地址跳转，跳转会有性能损耗，且由于局部性原理，指令会有预读机制，跳转之后可能导致cache miss，导致流水线失效
                * 验证方法  
                    编译的时候使用参数-fdump-lang-class，gdb调试的时候使用set print asm-demangle on，然后x/b打印地址
            * 虚继承
                同样使用到虚表，父类只有一份副本
                    
        * 智能指针
            
        * STL  
            两级情况，如果对象小于128K，则使用内存池，如果大于128K，则向系统申请空间，内存池使用链表维护
        * 构造函数
            1. 构造函数 （`A();`）
            2. 拷贝构造函数（`A(const A&);`）
            3. 析构函数（`~A();`）
            4. 重载赋值运算函数（`A& operator = (const A&);`）
            5. 重载取址运算函数（`A* operator & ();`）
            6. 重载取址const运算函数（`const A* operator & () const;`）
            7. 移动构造函数（`A(A&&);`）
            8. 重载移动复制函数（`A& operator = (const A&&);`）
        * 模板
            编译期按照实际的类型进行代码的动态扩展，遇到使用的新的模板类型的时候，就编译出对应的类型的代码。类似与在编译期对代码进行重载。
            * 模板参数除了类型，还支持整形，但是必须是常量
            * 模板使用的时候，会自动进行类型推导。无序声明参数
            * 模板是惰性编译的，只有使用到了才会编译。所以模板的实现最好写在一起
            * lambda也支持模板

        * 多线程内存模型
            * 线程
                线程运行时有单独的运行栈，如果是局部变量，则无数竞争的情况，如果有数据竞争的情况，则需要了解
                0. 缓存架构
                    多线程下数据竞争的问题几乎都是缓存导致，缓存当前普遍的模型是三层，L1L2单独对应cpu，L3对应一个核上的所有CPU，如果多线程的情况下，可能会有缓存不一致的情况，导致结果不符合预期，简单的例子是多线程的数据累加，解决方法是使用锁或者信号量或者把变量设置未原子类型。
                1. 指令重排
                    有几种情况，一是编译器优化，二是cpu优化，三是cpu的乱序执行，它可以在一个始终周期内执行多条指令，所以可能看起来是无序的
                2. 内存顺序
                3. volatile
                    在使用某个变量的时候，会直接从变量地址取数据，但是不保证更改的时候的原子性，所以上面0中的场景不可以使用volatile解决。本意是禁止变量的优化
    * 函数
        C++支持自定义对象，可以使用自己定义的函数，最终的是实现是把函数编译成为普通函数，只是函数的参数列表默认的会带上一个对象的指针，最底层实际上还是类似于C的面向过程。
    * 语法
    * 编译
    * STL
        * 容器
            简单的理解就是具体的数据结构的实现，然后提供了具体的实现方法，对于通用的函数，则单独使用算法实现，
            * 容器分类
                * 序列式
                    * array
                        数组，空间上连续，预分配空间。不可自动扩容，简单的数组的封装
                    * vector
                        解决array的问题，自动扩容，扩容时需要重新分配空间，然后移动数据到新空间，这个操作可能会导致迭代器失效，扩容因子不确定，有的是1.5倍增长，有的是2，扩容有性能问题，所以使用的时候明确场景，然后预先设置容量，避免扩容操作
                    * deque
                        双向队列，是用多段数组和一个控制中心实现的
                    * stack/queue
                        对列和栈，使用deque实现
                    * list
                        双向链表
                    * 单向链表
                * 关联式
                    * map
                        底层有一个隐藏的红黑树容器，存储键值对，按键排序
                    * set
                        同map，但是是键值和一的
            * 迭代器
                迭代器在删除数据的时候可能会导致失效问题，对于内存空间上连续的容器，由于删除之后需要其他的数据填补空洞，所以迭代器会移动到下一个位置，对于关联式容器，当前元素迭代器失效，需要手动记录下一个元素位置
            * 容器使用
        * 算法
            * STL中的一大项，由于是为了配合容器使用，所以几乎所有的算法都需要使用迭代器作为参数，然后大部分算法可以自行提供计算规则
    * 特性
        * 11新特性
    * GDB
        * 调试技巧

* 数据结构与算法        [3 天整理知识列表，长期进行]
    * 树
        * 二叉树
        * 堆
        * 234树
        * 红黑树
        * B树
        * B+树
    * hash
    * 线性表
        * 数组
        * 链表
        * 队列
        * 栈
    * 图
        * 存储方式
    * 跳表
    * LRU
    * 排序
    * dfs
    * bfs
    * 二分
    * ...


* 数据库                [3 天整理知识列表]
    * 编译
        * 编译原理
        * SQL编译过程
            词法分析 语法分析之后得到ast，然后使用元数据堆ast进行类型绑定，同时进行常规检查，类似语义分析
            * [词法分析](https://juejin.cn/post/6844904121506463758)  
              原文件分解为TOKEN，语法分析的前置，常见工具为lex
              * 一般不会一次生成所有TOKEN，而是和语法分析器结合使用，在进行语法分析的时候，需要单词的是时候才使用词法分析器生成TOKEN
            词法分析和语法分析的大致过程为先堆语句进行分词，生成token，常见的工具为yacc，然后使用语义分析工具接收tioken，进行语义检查且生成语法树，语法分析有几种分析方法，一是自底向上，二是自顶向下，
            * 文法
                * [LL(k)文法](https://blog.csdn.net/sinat_38816924/article/details/113749421)，第一个L指的是left to right，第二个L指的是最左推导
                * LR文法，R指的是最右推导，也成为最左规约
            * 自顶向下
                从token序列的最左端开始，读入token，然后匹配已有的规则，如果匹配到最后正在匹配的规则和输入不匹配，则进行回溯，匹配下一个可以匹配的规则，如果没有可以匹配的，则失败，特点是可能需要进行大量的回溯
                * 例from xx into 和 from xx where..，到后面解析不对需要回溯
            * 自底向上
                从输入的token开始，依次入栈，称为移进操作，然后如果栈中的数据可以匹配某规则，则使用规则替换，称为规约，反复进行此动作，直到生成一个语法树，每一次规约都会产生一个节点，此方法使用比较广泛，因为没有回溯操作，
                > https://zhuanlan.zhihu.com/p/94424139

            tip： SQL说到底也是一门语言，在编译阶段和其他的编译器结构类似，只是是可定制，大致分为前端和后端，对于前端，如果是老的项目，则只需要能添砖加瓦即可，
    * 优化
        * 优化规则
            * RBO
                基于规则的优化，基于经验主义，使用之前积累的优化的可以无条件优化的规则，实质上是关系代数的等价变换，变换的目的是尽可能的在下层把无用的数据消除掉，减少不必要的数据运算
                * 关系代数的优化
                    一些明显的可以减少运算数据的优化方法，例如谓词下推，先投影等
                * 子查询的优化
                    子查询会出现的位置是不一定的，在语句中，语义上他可以作为一张表来看，子查询分为关联子查询和非关联子查询
                    1. 关联子查询
                        子查询依赖外部属性
                    2. 非关联子查询
                        子查询独立存在
                    * 优化方法
                        最常用的方法是通过子查询展开消除子查询，把子查询变换为连接操作，然后进行连接操作的优化，如果没有聚合操作，大部分的语句可以优化
                * 谓词重写
                    对于一些谓词，使用其他等价规则重写，目的是为了更好的进行优化，例如like重写为大于and小于，in重写添加查询范围，any和all添加查询范围等。
                * 条件化简
                    目的是简化查询条件，便于优化，必要的时候需要重写表达式或者添加一些表达式
                * 视图重写 
                * 连接消除
                    * 外连接消除
                        原因是外连接的连接顺序是不可变的，所以尽可能的把外连接转换为内连接，可转换的条件是可空侧没有null值输出，则可以直接转换为内连接，例如可空侧使用is not null 限制，
                    * 内连接
                * [join](https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti)
                    * left join  
                      左表全部输出，右表匹配的输出，不匹配的为null
                    * right join
                      右表全部输出，左表匹配的输出，不匹配的为null
                    * inner join
                      输出匹配数据
                    * fulljoin  
                      left join  和right join的union
                    * semi join
                      分为left和right，只输出左表或者右表中与另一个表匹配的数据
                      * 语法  
                        in all exist some any
                    * anti join
                      输出不匹配的数据
                      * 语法  
                        not exist, not in

                    子查询，在上面的semijoin和antijoin的时候，某些情况可以转换，
                    外连接转内连接  
                      - 外表限定is not null
                    半连接转内连接
                      - 限定查询字段

                    [1](https://www.cnblogs.com/lovezhr/p/15855471.html#:~:text=%E7%94%A8%E6%96%87%E5%AD%97%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B%EF%BC%8C%E5%8F%AA%E6%9C%89%E7%AC%A6%E5%90%88%E4%B8%8B%E8%BE%B9%E8%BF%99%E4%BA%9B%E6%9D%A1%E4%BB%B6%E7%9A%84%E5%AD%90%E6%9F%A5%E8%AF%A2%E6%89%8D%E5%8F%AF%E4%BB%A5%E8%A2%AB%E8%BD%AC%E6%8D%A2%E4%B8%BA%20semi-join%EF%BC%9A%20%E8%AF%A5%E5%AD%90%E6%9F%A5%E8%AF%A2%E5%BF%85%E9%A1%BB%E6%98%AF%E5%92%8CIN%E8%AF%AD%E5%8F%A5%E7%BB%84%E6%88%90%E7%9A%84%E5%B8%83%E5%B0%94%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%9C%A8%E5%A4%96%E5%B1%82%E6%9F%A5%E8%AF%A2%E7%9A%84%20WHERE%20%E6%88%96%E8%80%85,ON%20%E5%AD%90%E5%8F%A5%E4%B8%AD%E5%87%BA%E7%8E%B0%20%E5%A4%96%E5%B1%82%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%8F%AF%E4%BB%A5%E6%9C%89%E5%85%B6%E4%BB%96%E7%9A%84%E6%90%9C%E7%B4%A2%E6%9D%A1%E4%BB%B6%EF%BC%8C%E5%8F%AA%E4%B8%8D%E8%BF%87%E5%92%8C%20IN%20%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%90%9C%E7%B4%A2%E6%9D%A1%E4%BB%B6%E5%BF%85%E9%A1%BB%E4%BD%BF%E7%94%A8AND%20%E8%BF%9E%E6%8E%A5%E8%B5%B7%E6%9D%A5)
                    [2](https://blog.csdn.net/xioayu96/article/details/107604338)
                    [3](https://zhuanlan.zhihu.com/p/382416772)
                * 案例
                  * calcite : CoreRules.java  
                    * FilterJoinRule 
                    ```
                        // (t1.a = 1 AND t2.a = 2) OR (t1.b = 3 AND t2.b = 4), you can
                        // derive table filters:
                        // (t1.a = 1 OR t1.b = 3)
                        // (t2.a = 2 OR t2.b = 4)
                    ```
            * CBO
                基于代价的优化，由于一个逻辑算子的物理实现可能有多个物理算子，所以需要在实际的使用场景中选择合适的物理算子，且在多个表达式的情况下，每个逻辑算子的最有的执行计划可能得到的结果也不是最优的，所以一般需要考虑数据统计信息，以及环境的io情况，内存大小，是否是分布式环境等，然后使用这些信息计算出cost最小的执行计划，cost只是一个变量，目的是为了对计划可以与一个具体的衡量指标
        * 优化框架  
            * https://zhuanlan.zhihu.com/p/73545345
            * https://zhuanlan.zhihu.com/p/464717139
            * 遗传算法
                pg默认在表数量大于13的时候使用遗传算法，可能得到的不是最优的执行计划，他是通过组合然后按计划代价排序，然后随机变异，淘汰最差解得到最后的执行计划的，不是全局最优解，但是搜索空间小，
            * 自底向上
                自底向上的动态规划算法，可以得到全局最优解，但是搜索空间巨大，PG只有在表数量小于13的时候使用此方法。
                * 初始化叶子节点，每个节点取得当前最优执行计划
                * 组合每个叶子节点的得到第二层，保留每个组合
                * 使用第一层和第二层组合得到第三层
                * 重复类似的方式得到最优解，在计算N层的时候，具体选取那一层暂时没有结论
                * 对于是否是order的，需要单独额外记录，否则底层选择的计划上层无法得知是否为最优的。
                * system R  
                  也是一种自底向上，但是只保留最优和次优解，用于上层的执行计划的生成，最后的执行计划可能不是全局最优
            * Volcano  [The Volcano Optimizer Generator: Extensibility and Efficient Search  http://www.cse.iitb.ac.in/infolab/Data/Courses/CS632/Papers/Volcano-graefe.pdf]
            * Cascades
                * expression
                    有逻辑表达式和物理表达式，他们在group中是等价的  
                * group
                    等价表达式的集合，等价的意思是他们的输入和输出是一样的
                * rule
                    对group的变换规则，有物理算子的实现规则，有逻辑算子的转换规则，目的是为了扩大搜索空间
                * memo
                    搜岁空间，存放group
                1. 首先初始化搜索空间，即初始化所有group
                2. 从根节点开始，然后使用rule扩展搜索空间
                3. 使用dfs搜索
                4. 可以设置代价阈值，搜索时间限制等，使优化过程提前终止  
                  group中是等价表达式，在优化group的时候，有表达式已经优化，在优化其他表达式的时候，如果过程中代价已经超出了之前记录的代价，则可以停止继续优化此表达式
                5. 可以自行指定执行计划

                * calcate | nosiepage | pg 
    * 执行
        * 算子实现  
            * join
                * merge join  
                    如果表是有序的，则优先选择merge join，否则数据无序且强行走merge join的话，会导致数据进行排序，可能会有极大的性能损耗
                * hash join  
                    1. 小表作为驱动表，构造hash表，然后使用此hash表对另一个表进行hash，如果存在，则匹配成功，此步称为probe|探测。代价主要是两个表的full scan和hash表的内存以及建立hash 的时间  
                    2. 如果都是大表且内存无法方法构建之后的hash表，有几种方法  
                        1. 先对原表进行分区，然后再对各个分区单独进行hash匹配，相比之前，代价是被驱动表的full scan*n 和驱动表的scan和内存损耗  
                        2. 同时对两表使用相同的分区方式进行分区，然后在各自的分区内进行hash，相比上面的方法，这里可以使用多线程或者多进程进行处理  
                * nest loop join  
                    小表驱动大表，小表读取一行数据之后，使用此行数据到被驱动表进行匹配，所以如果被驱动表的对应的键只是普通的键的话，可能会全表扫面，所以需要被驱动表有index或者键是主键等可以直接按照key定位数据的表，代价为n*m + n  
                * 如过是分布式的环境，则可能有数据的跨界点的传输的情况，有一张IO时间的表格表示，网络io的时间是非常长的，所以需要尽可能的保证数据在当前节点进行计算。如果必须传输数据，则  
                    1. 小表进行广播，各节点使用小表join  
                    2. 常规的join运算  
                    但是如果在表分区的是否，可以保证join的数据在同于一个分区上是相同的分区方式，则可以直接本节点join然后汇总数据，clickhouse的分区可以实现这种需求，分区对其  
            * sort  
                排序，数据是按块操作的，可以使用merge sort，也可以通过在内存中构造一个有序的数据结构然后输出，如果内存放不下数据，则可以把数据临时放在内存外，另外，由于是按块操作的，所以可以在块中存放当前块的min max，可以使用此信息加速排序等。  
            * 窗口函数  
                https://zhuanlan.zhihu.com/p/80051518  
            * 常规函数  
        * 执行框架  
            * 火山模型/Volcano   
                每个算子实现next，open,close方法，tuple-at-a-time类似于迭代器，用于向上层节点向下层节点拉取数据，早期cpu和mem的新能还在增长所以当时这种技术几乎是首选，运行是时间耗时主要为io，且由于大量next的调用，都会导致流水线被破坏。  
        * 向量化  
            简单理解就是每个算子批量处理数据，早期的Volcano 模型的单行处理，会导致缓存，指令调度，分支预测错误等导致性能下降，在TP的场景中最为明显，因为AP是行存的，所以为了解决这些问题， MonetDB/X100: Hyper-Pipelining Query Execution提出vector-at-a-time执行模式，大致方向为：  
            * 保持Volcano模型大致结构基本不变，但是原来的tuple保存一行的操作使用vector替代，保存列，数据大小尽量可以都放在缓存中    
                所以他更多的适用于列存，行存也可以使用类似的方法来加速，但是可能效果没有列存优秀  
            * 使用向量化原语计算  
                上下文无关的计算逻辑，专门计算vector的数据  
            * 使用延迟物化技术减少内存的读写开销  
                记录vector中的数据变动，尽可能晚的变动内存中的数据  
            * 使用代码生成来避免类型转换代码的大量代码分支  
            * CPU在计算同类型数据的时候更容易使用simd优化   
            TIPS:  
                1. 分支预测，局部性原理，会预加载多条指令，在遇到代码跳转的时候，清空当前流水线，加载其他流水线，导致性能问题，典型的场景是排序一组有序数据和无序数据之间的差距明显  
                2. cache miss，使用的数据不在缓存中，需要去内存中读取，记得之前有测试AOS，SOA之间的差距可以达到四五倍  
        * codegen  
            把执行计划中不需要物化的算子实现为一个表达式，而不是以task的方式调度，具体实现为：  
            1. 对于算子树，使用深度优先遍历，生成一段代码  
            2. 对于Volcano模型来说，就是task算子的调用层级是现在一段代码逻辑中  
            3. 数据流动的时候可以直接存储在寄存器中，而不需要物化操作  
            4. 对于block算子，则必须物化  
            5. 由底层节点开始，向上推送数据  
            6. 适合计算场景，可以优化代码，提升寄存器的利用率  

            所以对于一个执行计划，codegen的就是把他实现为一个整体，而不是Volcano类似的面对对象的实现  

        [Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask https://www.bilibili.com/video/av50329586/]
        案例：
            tidb使用的是向量化，即使它使用的是行存，他会在数据读取出来之后转换数据模式为vector，以便于使用向量化  

          * 计算密集型，优先使用codegen，因为可以把数据缓存在寄存器中


    * 存储
        * 存储格式
            * 行存
            * 列存
        * 存储的数据结构  【LSM https://www.yuque.com/earayu/kkdi0n/gqibsf#pSa3E】  
            LSM  
                * 起源  
                    - B+tree的异地更新，定期合并，垃圾回收，顺序写，最先由PG实现，但是由于实现复杂，所以后续的LSM重新设计了数据结构  
                * 数据分层  
                    使用sstable保存数据，在内存中是memetable，在磁盘中是sstable，磁盘中sstable只是写，达到一定大小的时候和下层进行合并，典型的实现是leveldb  
                * 写  
                    保证数据安全，先写wal  
                    写内存中的memtable，当数据满之后。固化memtable  
                    memtable落盘，落盘成功之后释放之前的WAL  
                    如果此时磁盘中顶层的数据达到限定的阈值，则挑选一个sstable向下层compact，直到所有层都满足要求  
                * 读  
                    从内存中的memtable读取数据  
                    内存中没有则在磁盘中按层次查找  
                    sstable可以使用额外的信息加速查找  
                * 问题  
                    在写的时候会有多次IO操作，如果后台进行compact的时候，会导致前端的吞吐量，查询的时候会由读放大问题。 
                * compact  
                    定期compact
                    * memtable 落盘是minor compcat。构造sstable 落盘，会占用一定的cpu和IO，leveldb此时是在适当的暂停写操作
                    * sstable 合并是Major compact，
            LSM 优化  
                LSM适用于HDD，当前SSD中随机读写和顺序读写几乎无太大差距  
            B+tree  
                * 起源  
                    目的是为了降低从磁盘中查询数据时候的次数  
                * 组织结构  
                    按页大小为单位组织节点，逻辑上的树形结构，树的高度与数据的多少有关，节点满的时候进行分裂  
                * 操作  
                    读取的时候按页读取，从根节点开始，定位到子页的时候再去读取子叶，直到叶子节点被读取，页的大小是4KB，假设key为8，地址大小为8，则一组key大小为16，则一页可以指向256页，则两层树高的树可以保存1kw的数据，此时磁盘io只有三次  
                    写的时候会检测节点时候full，如果full，则需要split，如果当前层满了，则增加树的高度，  
                * 随机读性能高。如果没有额外的设计，则没有读写放大的问题，且易于实现lock，但是由于写的时候可能会导致树的变化，会有性能问题  
        * 事务 
            * 特性ACID   
                - A 原子性  
                - C 一致性  
                - I 隔离性  
                    - 隔离级别  
                     * 读未提交
                        - 脏读
                            - 长时间持有写锁，短时间持有读锁，只能读取别人已经释放锁的数据
                     * 读已提交
                        - 不可重复读
                            - 长时间持有读锁和写锁，保持数据独占
                     * 快照都
                     * 可重复读
                        - 幻读
                     * 串行化
                     * 写偏序
                        * 另一个事务修改数据，导致某事物在处理的数据的时候约束条件改变

                                            
                - D 持久性  

    * 案例  
        * leveldb
        * pg
        * trafodion
        * mysql

* linux                 [2 天整理知识列表  https://www.bookstack.cn/books/webxiaohua-gitbook]
    * 进程，线程
        可以通过init创建，也可以使用fork从父进程创建，fork返回值为0，则是子进程，子进程创建的时候使用写拷贝技术，初始化的时候除了pcb之外，其余的内存呢地址和父进程是一起的，只有当子进程需要修改的时候，才会copy修改为到自己的内存中去，
        * 调度方法
            抢占式和非抢占式
            时间片
            先进先出
            短作业优先
            长作业优先
            最短剩余时间优先等
        * 通信
        * 内存结构
            * 虚拟内存
                为了给进程提供一个连续的内存空间，逻辑上连续，物理上不一定连续，由于进程的使用会申请和释放空间且空间有有限的，所以需要把一些页面置换出去
                1. 最佳置换
                    把以后不会使用的页面置换掉，但是无法实现，不能保证那些页面不会使用
                2. 先进先出
                3. 时钟置换
                4. 最近最久未使用
                    置换最长时间没有使用的页面
                局部性原理，时间局部性和空间局部性，在操作各种资源的时候，可以把当前资源附近的资源一起使用，附近可以是空间，也可以是时间
            * 共享内存
                所有页面都映射到相同的内存空间，多进程使用的时候存在竞争问题
            * 内存碎片
                内存可能会导致总体空足够，但是无法申请空间的问题，所以需要较为合适的内存分配算法，内存一般使用链表或者其他类似的数据结构维护
                1. 首次适应
                    从链表的首段开始找到合适的内存
                2. 最佳适应
                    从链表的首段开始，找到最合适的空间
                3. 最大适应
                    查找到最大的内存空间，从他上面分配内存
                4. 临近适应
                    从当前的使用位置开始，寻找合适的空间
        * 进程间通信
            * 线程由于公用地址空间，所以线程可以直接通信，进程由于资源隔离，所以需要额外的通信机制
                1. 匿名管道
                    存在在父子进程中，因为fork之后的父子进程具有相同的内存印象，所以可以直接使用
                2. 命名管道
                    有名的管道，知道名字之后任意进程可以直接使用 mkfifo
                3. 消息队列
                    一个本质时存放在内核中的链表，消息发送和取消的时候遵循先进先出
                4. 共享内存
                    所有进程都会映射共享内存，所以可以借助它进行通信
                5. 信号量

    * 协程
        简单的理解就是函数调用的状态机？他会记录运行时的状态，在多个执行线路之间进行跳转。一种实现思路时使用堆区维护协程运行context，然后在协程调用的时候记录信息即可。出现时间早，C++最早面世的时候时支持协程的，d大致是在1980s左右，因为当时计算机没有线程的实现，而进程并发代价大，所以协程-用户态线程就出现了，
    * IO多路复用
        单线程同时检测多io
        select
            底层使用数组保存fd，默认大小为1024，所以有操作上限，在使用的时候需要把数组从内核拷贝到用户空间
        poll
            对select 的改进，底层替换为链表，使用的时候，需要遍历链表
        epoll
            使用回调机制，当io完成之后放入就绪链表，使用预先注册的回调函数通知用户
            
    * 线程
        资源使用的基本单位，进程中的线程公用地址空间，生命周期和进程有关，运行时每一个线程都有自己的运行栈
    * 同步/异步
    * 并发/并行


* 分布式                [2 天整理知识列表]
    * 共识协议
        * raft
          分布式共识算法
          * 成员选举
          * 日志复制
          * 安全性
        * posie

* TPC
  一个组织，发布多项测试基准，用于测试SQL完整性和正确性及性能，
  * TPC-DS  
    较新的测试基准，场景更贴合实际，但是大部分数据库不公布此测试结果，因为此测试涵盖范围广，大部分数据库要么性能达不到，要么语句不支持
  * TPC-H
    可以通过index hack此测试，所以不能完全反映性能，但是SQL场景简单，

* 大数据                [2 天整理知识列表]
    * Hadoop
    * spark
    * hdfs
    * hive
    * scala


* 项目经历              [1 天整理知识列表] -- 大厂扯皮必备
    * 分区表
        range分区，负责index的维护，split分区，同时后期维护整个分区表的dml实现
        * index
            * global index
                一个分区表对应一个index，在使用的时候，例如index的全表查询等，就会使用GI
            * local index
                一个分区对应一个index，在查询单个分区的时候，就会使用此index
        * split
            分裂分区，要求可以分裂任意分区，包括混合分区
        * dml
            * select
                分区查询，按照查询条件决定从那个分区查询，有跨分区的情况
            * insert
                分区insert，无法限定insert的数据来源的边界，所以需要全表的分区都进行insert
            * update

            * delete
    * 临时表

    * 只读表
        数据预加载进缓存，然后从缓存读取 [
	  当前为只读，后期设计为懒同步，即数据访问从
	]
        * 难点
            数据存储模型
                memtableDB      维护内存中的表，使用的是hash表，key为table name，values为table
                - table         维护一个table对象，使用的是array，数据顺序和原表数据顺序一致
                 - row          行数据
                内存使用
                    使用内置的内存池，便于计算空间使用率
            多节点之间的数据同步，数据维护
                * 数据预加载的时候堆表加dml和ddl锁，防止期间外部操作数据变动
                * 提供数据一致性检测语法
                    之前设计的时候，只是想简单的比对数据
                    之后有一个想法，数据存储在hbase中，暂时没有找到hbase有没有所有数据的checksum实现，没有的话自行实现，然后memtable 中也实现一个checksum，比对的时候直接检测checksum即可，可以在每次查询的时候进行比对
                        * 原表数据变动的时候，由于存储的架构问题，所以可以完整的追踪每个数据的变化，同时计算checksum
            多节点数据预加载时候的查询
                存在节点重启或者节点添加或者人工运维只读表的情况，此时禁止读取，使用锁，对共享内存加锁，禁止其他任何操作
        * 性能
            聚合语句的直接提升为上百倍

    * 大字段优化
        * 收获最大                      -- 假装
            * 范围广，所以追踪数据流向，加快了解项目的执行逻辑
            * 知道了执行引擎执行逻辑         -- 火山模型
    * bug fix
